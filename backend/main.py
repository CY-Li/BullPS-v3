import sys
from pathlib import Path

# å°‡å°ˆæ¡ˆæ ¹ç›®éŒ„æ·»åŠ åˆ° Python è·¯å¾‘
# ç¢ºä¿å³ä½¿ç›´æ¥é‹è¡Œ main.py ä¹Ÿèƒ½æ‰¾åˆ° backend æ¨¡çµ„
BASE_DIR = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(BASE_DIR))

from fastapi import FastAPI, BackgroundTasks, Request, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from starlette.responses import FileResponse, JSONResponse, Response
from contextlib import asynccontextmanager
import subprocess
import json
import math

from pathlib import Path
from datetime import datetime
import os
import logging
import time
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
import pytz

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@asynccontextmanager
async def lifespan(app: FastAPI):
    # å•Ÿå‹•æ™‚åŸ·è¡Œ
    # æ¯å¤©æ—©ä¸Š6é»ï¼ˆAsia/Taipeiï¼‰åŸ·è¡Œ
    scheduler.add_job(scheduled_task, CronTrigger(hour=6, minute=0))
    scheduler.start()
    logger.info("Scheduler started")

    yield

    # é—œé–‰æ™‚åŸ·è¡Œ
    scheduler.shutdown()
    logger.info("Scheduler shutdown")

app = FastAPI(lifespan=lifespan)

# æª”æ¡ˆè·¯å¾‘
BASE_DIR = Path(__file__).parent.parent

# ä½¿ç”¨çµ±ä¸€çš„è·¯å¾‘ç®¡ç†å™¨
try:
    from backend.path_manager import path_manager
    ANALYSIS_PATH = path_manager.get_analysis_path()
    MONITORED_STOCKS_PATH = path_manager.get_monitored_stocks_path()
    TRADE_HISTORY_PATH = path_manager.get_trade_history_path()
    logger.info(f"Using path_manager - Analysis: {ANALYSIS_PATH}, Monitored: {MONITORED_STOCKS_PATH}, Trade History: {TRADE_HISTORY_PATH}")
except ImportError as e:
    logger.warning(f"Failed to import path_manager: {e}, using fallback paths")
    # å›é€€åˆ°åŸå§‹è·¯å¾‘é‚è¼¯
    if os.path.exists("/app"):
        ANALYSIS_PATH = Path("/app/analysis_result.json")
        MONITORED_STOCKS_PATH = Path("/app/monitored_stocks.json")
        TRADE_HISTORY_PATH = Path("/app/trade_history.json")
    else:
        ANALYSIS_PATH = BASE_DIR / "analysis_result.json"
        MONITORED_STOCKS_PATH = BASE_DIR / "monitored_stocks.json"
        TRADE_HISTORY_PATH = BASE_DIR / "trade_history.json"
    logger.info(f"Using fallback paths - Analysis: {ANALYSIS_PATH}, Monitored: {MONITORED_STOCKS_PATH}, Trade History: {TRADE_HISTORY_PATH}")

STATIC_DIR = BASE_DIR / "frontend" / "dist"


# å…¨å±€ç‹€æ…‹è®Šæ•¸
analysis_status = {
    "is_running": False,
    "current_stage": "",
    "progress": 0,
    "message": "",
    "start_time": None,
    "end_time": None,
    "error": None
}

# ç¢ºä¿æª”æ¡ˆå­˜åœ¨ä¸¦æ ¼å¼æ­£ç¢º
def ensure_json_file_exists(file_path, default_content):
    """ç¢ºä¿ JSON æ–‡ä»¶å­˜åœ¨ä¸”æ ¼å¼æ­£ç¢º"""
    try:
        if not file_path.exists():
            logger.warning(f"File not found at {file_path}, creating with default content")
            try:
                file_path.write_text(json.dumps(default_content), encoding='utf-8')
            except (PermissionError, OSError) as e:
                logger.error(f"Cannot create file {file_path}: {e}")
                return
        else:
            # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦ç‚ºæœ‰æ•ˆ JSON
            content = file_path.read_text(encoding='utf-8').strip()
            if not content:
                logger.warning(f"File {file_path} is empty, initializing with default content")
                try:
                    file_path.write_text(json.dumps(default_content), encoding='utf-8')
                except (PermissionError, OSError) as e:
                    logger.error(f"Cannot write to file {file_path}: {e}")
                    return
            else:
                try:
                    json.loads(content)
                except json.JSONDecodeError:
                    logger.warning(f"File {file_path} contains invalid JSON, reinitializing")
                    try:
                        file_path.write_text(json.dumps(default_content), encoding='utf-8')
                    except (PermissionError, OSError) as e:
                        logger.error(f"Cannot write to file {file_path}: {e}")
                        return
    except Exception as e:
        logger.error(f"Error ensuring file {file_path}: {e}")
        try:
            file_path.write_text(json.dumps(default_content), encoding='utf-8')
        except (PermissionError, OSError) as write_error:
            logger.error(f"Cannot write to file {file_path}: {write_error}")

# åˆå§‹åŒ–æ‰€æœ‰å¿…è¦çš„ JSON æ–‡ä»¶
ensure_json_file_exists(ANALYSIS_PATH, {"result": []})
ensure_json_file_exists(MONITORED_STOCKS_PATH, [])
ensure_json_file_exists(TRADE_HISTORY_PATH, [])

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# è¨­å®šå°åŒ—æ™‚å€
TZ_TAIPEI = pytz.timezone('Asia/Taipei')

def update_status(stage: str, progress: int, message: str):
    """æ›´æ–°åˆ†æç‹€æ…‹"""
    global analysis_status
    analysis_status.update({
        "current_stage": stage,
        "progress": progress,
        "message": message,
        "is_running": True
    })
    logger.info(f"Stage: {stage} - {message} ({progress}%)")

def clean_nans(obj):
    if isinstance(obj, float) and math.isnan(obj):
        return None
    elif isinstance(obj, dict):
        return {k: clean_nans(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [clean_nans(x) for x in obj]
    else:
        return obj



def run_stock_analysis():
    """åŸ·è¡Œè‚¡ç¥¨åˆ†æå™¨ï¼Œä¸¦å›å ±è©³ç´°ç‹€æ…‹"""
    global analysis_status
    
    try:
        # åˆå§‹åŒ–ç‹€æ…‹
        analysis_status.update({
            "is_running": True,
            "current_stage": "",
            "progress": 0,
            "message": "",
            "start_time": datetime.now(TZ_TAIPEI).isoformat(),
            "end_time": None,
            "error": None
        })
        
        # èª¿æ•´å·¥ä½œç›®éŒ„åˆ°å°ˆæ¡ˆæ ¹ç›®éŒ„
        os.chdir(BASE_DIR)
        
        # éšæ®µ1: æ•¸æ“šç²å–èˆ‡åˆ†æ
        update_status("æ­£åœ¨åˆ†æè‚¡ç¥¨...", 30, "æ•¸æ“šåˆ†æä¸­")
        subprocess.run(["python", "integrated_stock_analyzer.py"], check=True, cwd=BASE_DIR)
        
        # éšæ®µ2.5: æ¯”å°ä¸¦æ›´æ–°ç›£æ§ä¸­çš„è‚¡ç¥¨åˆ†æå¿«ç…§
        update_status("æ­£åœ¨æ¯”å°ä¸¦æ›´æ–°ç›£æ§è‚¡ç¥¨åˆ†æå¿«ç…§...", 65, "æ•¸æ“šæ¯”å°ä¸­")
        # ç›´æ¥èª¿ç”¨ portfolio_manager ä¸­çš„å‡½æ•¸ï¼Œè€Œä¸æ˜¯ä½œç‚ºç¨ç«‹é€²ç¨‹
        from backend.portfolio_manager import compare_and_update_monitored_stocks
        compare_and_update_monitored_stocks()
        
        # éšæ®µ3: æŠ•è³‡çµ„åˆç®¡ç†
        update_status("æ­£åœ¨æª¢æŸ¥æŒå€‰èˆ‡æ›´æ–°äº¤æ˜“ç´€éŒ„...", 80, "æŠ•è³‡çµ„åˆç®¡ç†ä¸­")
        subprocess.run(["python", "backend/portfolio_manager.py"], check=True, cwd=BASE_DIR, env=os.environ)
        
        # éšæ®µ4: å ±å‘Šç”Ÿæˆä¸­
        update_status("æ­£åœ¨ç”Ÿæˆæœ€çµ‚å ±å‘Š...", 95, "å ±å‘Šç”Ÿæˆä¸­")
        time.sleep(1)
        
        # å®Œæˆ
        analysis_status.update({
            "is_running": False,
            "current_stage": "å®Œæˆ",
            "progress": 100,
            "message": "åˆ†æèˆ‡ç®¡ç†å®Œæˆ",
            "end_time": datetime.now(TZ_TAIPEI).isoformat()
        })
        
        logger.info("Analysis and portfolio management completed successfully")
        
    except Exception as e:
        analysis_status.update({
            "is_running": False,
            "current_stage": "éŒ¯èª¤",
            "progress": 0,
            "message": f"åŸ·è¡Œå¤±æ•—: {str(e)}",
            "end_time": datetime.now(TZ_TAIPEI).isoformat(),
            "error": str(e)
        })
        logger.error(f"Error during execution: {e}")
        raise

scheduler = BackgroundScheduler(timezone=pytz.timezone('Asia/Taipei'))

def scheduled_task():
    try:
        run_stock_analysis()
    except Exception as e:
        logger.error(f"Error in scheduled task: {e}")



@app.get("/api/health")
def health_check():
    try:
        from backend.path_manager import path_manager
        path_info = path_manager.get_info()
    except Exception as e:
        path_info = {
            "error": f"Path manager failed: {e}",
            "fallback_paths": {
                "analysis": str(ANALYSIS_PATH),
                "monitored_stocks": str(MONITORED_STOCKS_PATH),
                "trade_history": str(TRADE_HISTORY_PATH)
            },
            "fallback_exists": {
                "analysis": ANALYSIS_PATH.exists(),
                "monitored_stocks": MONITORED_STOCKS_PATH.exists(),
                "trade_history": TRADE_HISTORY_PATH.exists()
            }
        }

    return {
        "status": "healthy",
        "timestamp": datetime.now(TZ_TAIPEI).isoformat(),
        "path_manager_info": path_info,
        "static_dir_exists": STATIC_DIR.exists(),
        "static_dir_path": str(STATIC_DIR),
        "files_in_static": os.listdir(STATIC_DIR) if STATIC_DIR.exists() else []
    }

@app.get("/api/analysis-status")
def get_analysis_status():
    """ç²å–ç•¶å‰åˆ†æç‹€æ…‹"""
    return analysis_status

@app.post("/api/run-now")
def run_now(background_tasks: BackgroundTasks):
    """è§¸ç™¼ç«‹å³åˆ†æ"""
    if analysis_status["is_running"]:
        return {"status": "already_running", "message": "åˆ†ææ­£åœ¨é€²è¡Œä¸­"}

    logger.info("Manual analysis triggered via API")
    background_tasks.add_task(run_stock_analysis)
    return {"status": "started", "message": "åˆ†æå·²é–‹å§‹"}

@app.get("/api/trigger-analysis")
def trigger_analysis_get(background_tasks: BackgroundTasks):
    """GETæ–¹å¼è§¸ç™¼åˆ†æï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰"""
    if analysis_status["is_running"]:
        return {"status": "already_running", "message": "åˆ†ææ­£åœ¨é€²è¡Œä¸­"}

    logger.info("Analysis triggered via GET endpoint")
    background_tasks.add_task(run_stock_analysis)
    return {"status": "started", "message": "åˆ†æå·²é–‹å§‹"}

@app.get("/api/debug-files")
def debug_files():
    """èª¿è©¦ç«¯é»ï¼šæª¢æŸ¥æ‰€æœ‰å¯èƒ½çš„æ–‡ä»¶ä½ç½®"""
    import glob

    debug_info = {
        "current_paths": {
            "analysis": str(ANALYSIS_PATH),
            "monitored_stocks": str(MONITORED_STOCKS_PATH),
            "trade_history": str(TRADE_HISTORY_PATH)
        },
        "file_exists": {
            "analysis": ANALYSIS_PATH.exists(),
            "monitored_stocks": MONITORED_STOCKS_PATH.exists(),
            "trade_history": TRADE_HISTORY_PATH.exists()
        },
        "file_sizes": {},
        "all_json_files": []
    }

    # æª¢æŸ¥æ–‡ä»¶å¤§å°
    for name, path in [("analysis", ANALYSIS_PATH), ("monitored_stocks", MONITORED_STOCKS_PATH), ("trade_history", TRADE_HISTORY_PATH)]:
        try:
            debug_info["file_sizes"][name] = path.stat().st_size if path.exists() else 0
        except Exception as e:
            debug_info["file_sizes"][name] = f"Error: {e}"

    # æŸ¥æ‰¾æ‰€æœ‰ JSON æ–‡ä»¶
    search_patterns = [
        "/app/**/*.json",
        "/app/*.json",
        "/app/backend/*.json",
        "*.json",
        "backend/*.json"
    ]

    for pattern in search_patterns:
        try:
            files = glob.glob(pattern, recursive=True)
            for file in files:
                if file not in debug_info["all_json_files"]:
                    try:
                        size = os.path.getsize(file)
                        debug_info["all_json_files"].append(f"{file} ({size} bytes)")
                    except:
                        debug_info["all_json_files"].append(f"{file} (size unknown)")
        except Exception as e:
            debug_info["all_json_files"].append(f"Error searching {pattern}: {e}")

    return debug_info



@app.get("/api/analysis")
def get_analysis():
    try:
        logger.info(f"Checking analysis file at: {ANALYSIS_PATH}")
        logger.info(f"File exists: {ANALYSIS_PATH.exists()}")

        if ANALYSIS_PATH.exists():
            content = ANALYSIS_PATH.read_text(encoding='utf-8').strip()
            if not content:
                logger.warning("Analysis file is empty")
                return {"result": [], "error": "Analysis file is empty"}

            data = json.loads(content)
            cleaned_data = clean_nans(data)
            logger.info(f"Analysis data loaded successfully, result count: {len(cleaned_data.get('result', []))}")
            return cleaned_data
        else:
            logger.warning(f"Analysis file not found at: {ANALYSIS_PATH}")
            # å˜—è©¦å‰µå»ºç©ºçš„åˆ†æçµæœæ–‡ä»¶
            try:
                ANALYSIS_PATH.parent.mkdir(parents=True, exist_ok=True)
                empty_result = {"result": [], "timestamp": "", "analysis_date": "", "total_stocks": 0, "analyzed_stocks": 0}
                ANALYSIS_PATH.write_text(json.dumps(empty_result), encoding='utf-8')
                logger.info(f"Created empty analysis file at: {ANALYSIS_PATH}")
                return empty_result
            except (PermissionError, OSError) as create_error:
                logger.error(f"Permission denied creating analysis file: {create_error}")
                return {"result": [], "error": "Analysis file not found and permission denied to create"}
            except Exception as create_error:
                logger.error(f"Failed to create analysis file: {create_error}")
                return {"result": [], "error": "Analysis file not found and could not be created"}
    except json.JSONDecodeError as e:
        logger.error(f"JSON decode error in analysis file: {e}")
        return {"result": [], "error": "Invalid JSON in analysis file"}
    except Exception as e:
        logger.error(f"Error reading analysis: {e}")
        return JSONResponse(
            status_code=500,
            content={"error": "Failed to read analysis"}
        )

@app.get("/api/monitored-stocks")
def get_monitored_stocks():
    try:
        if MONITORED_STOCKS_PATH.exists():
            content = MONITORED_STOCKS_PATH.read_text(encoding='utf-8').strip()
            if not content:
                # æ–‡ä»¶ç‚ºç©ºï¼Œå‰µå»ºç©ºæ•¸çµ„
                logger.warning("monitored_stocks.json is empty, initializing with empty array")
                try:
                    MONITORED_STOCKS_PATH.write_text("[]", encoding='utf-8')
                except (PermissionError, OSError) as e:
                    logger.error(f"Cannot write to monitored_stocks.json: {e}")
                return []

            data = json.loads(content)
            # If data is a dictionary, convert its values to a list
            if isinstance(data, dict):
                return list(data.values())
            return data
        else:
            # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå‰µå»ºç©ºæ•¸çµ„
            logger.warning("monitored_stocks.json does not exist, creating with empty array")
            try:
                MONITORED_STOCKS_PATH.write_text("[]", encoding='utf-8')
            except (PermissionError, OSError) as e:
                logger.error(f"Cannot create monitored_stocks.json: {e}")
            return []
    except json.JSONDecodeError as e:
        logger.error(f"JSON decode error in monitored stocks: {e}")
        # JSON æ ¼å¼éŒ¯èª¤ï¼Œé‡æ–°åˆå§‹åŒ–ç‚ºç©ºæ•¸çµ„
        try:
            MONITORED_STOCKS_PATH.write_text("[]", encoding='utf-8')
        except (PermissionError, OSError) as write_error:
            logger.error(f"Cannot write to monitored_stocks.json: {write_error}")
        return []
    except Exception as e:
        logger.error(f"Error reading monitored stocks: {e}")
        return JSONResponse(
            status_code=500,
            content={"error": "Failed to read monitored stocks"}
        )

@app.get("/api/trade-history")
def get_trade_history():
    try:
        if TRADE_HISTORY_PATH.exists():
            data = json.loads(TRADE_HISTORY_PATH.read_text(encoding='utf-8'))
            return data
        return []
    except Exception as e:
        logger.error(f"Error reading trade history: {e}")
        return JSONResponse(
            status_code=500,
            content={"error": "Failed to read trade history"}
        )





@app.get("/api/file-paths-status")
def get_file_paths_status():
    """ç²å–ç•¶å‰æ–‡ä»¶è·¯å¾‘ç‹€æ…‹"""
    try:
        import os
        from pathlib import Path

        # æª¢æŸ¥è·¯å¾‘ç®¡ç†å™¨ç‹€æ…‹
        try:
            from backend.path_manager import path_manager
            path_info = path_manager.get_info()
        except ImportError:
            path_info = {"error": "è·¯å¾‘ç®¡ç†å™¨ä¸å¯ç”¨"}

        # æª¢æŸ¥å¯¦éš›ä½¿ç”¨çš„æ–‡ä»¶è·¯å¾‘
        actual_paths = {
            "analysis_path": str(ANALYSIS_PATH),
            "monitored_stocks_path": str(MONITORED_STOCKS_PATH),
            "trade_history_path": str(TRADE_HISTORY_PATH)
        }

        # æª¢æŸ¥æ–‡ä»¶ç‹€æ…‹
        file_status = {}
        for name, path_str in actual_paths.items():
            path = Path(path_str)
            file_status[name] = {
                "path": path_str,
                "exists": path.exists(),
                "readable": False,
                "writable": False,
                "size": 0
            }

            if path.exists():
                try:
                    # æ¸¬è©¦è®€å–
                    content = path.read_text(encoding='utf-8')
                    file_status[name]["readable"] = True
                    file_status[name]["size"] = len(content)

                    # æ¸¬è©¦å¯«å…¥
                    path.write_text(content, encoding='utf-8')
                    file_status[name]["writable"] = True
                except Exception as e:
                    file_status[name]["error"] = str(e)

        # æª¢æŸ¥å‚™ä»½ç›®éŒ„
        backup_dir = Path("/tmp/bullps_data")
        backup_status = {
            "exists": backup_dir.exists(),
            "writable": False,
            "files": {}
        }

        if backup_dir.exists():
            try:
                test_file = backup_dir / "test.tmp"
                test_file.write_text("test")
                test_file.unlink()
                backup_status["writable"] = True
            except Exception:
                pass

            # æª¢æŸ¥å‚™ä»½æ–‡ä»¶
            for filename in ["monitored_stocks.json", "trade_history.json", "analysis_result.json"]:
                backup_file = backup_dir / filename
                backup_status["files"][filename] = {
                    "exists": backup_file.exists(),
                    "size": backup_file.stat().st_size if backup_file.exists() else 0
                }

        return {
            "status": "success",
            "timestamp": datetime.now(TZ_TAIPEI).isoformat(),
            "path_manager_info": path_info,
            "actual_paths": actual_paths,
            "file_status": file_status,
            "backup_status": backup_status,
            "environment": {
                "container_env": os.environ.get("CONTAINER_ENV"),
                "zeabur": os.environ.get("ZEABUR"),
                "hostname": os.environ.get("HOSTNAME"),
                "backup_dir_env": os.environ.get("BULLPS_BACKUP_DIR")
            }
        }

    except Exception as e:
        logger.error(f"Error in get_file_paths_status: {e}")
        return JSONResponse(
            status_code=500,
            content={"error": f"ç²å–æ–‡ä»¶è·¯å¾‘ç‹€æ…‹å¤±æ•—: {str(e)}"}
        )

@app.post("/api/import-monitored-stocks")
async def import_monitored_stocks(file: UploadFile = File(...)):
    """åŒ¯å…¥ç›£æ§è‚¡ç¥¨æ•¸æ“š"""
    try:
        # é©—è­‰æ–‡ä»¶é¡å‹
        if not file.filename.endswith('.json'):
            return JSONResponse(
                status_code=400,
                content={"error": "åªæ”¯æ´ JSON æ–‡ä»¶æ ¼å¼"}
            )

        # è®€å–æ–‡ä»¶å…§å®¹
        content = await file.read()

        # é©—è­‰ JSON æ ¼å¼
        try:
            data = json.loads(content.decode('utf-8'))
        except json.JSONDecodeError as e:
            return JSONResponse(
                status_code=400,
                content={"error": f"JSON æ ¼å¼éŒ¯èª¤: {str(e)}"}
            )

        # é©—è­‰æ•¸æ“šçµæ§‹
        if not isinstance(data, list):
            return JSONResponse(
                status_code=400,
                content={"error": "æ•¸æ“šæ ¼å¼éŒ¯èª¤ï¼šæ‡‰ç‚ºè‚¡ç¥¨åˆ—è¡¨æ•¸çµ„"}
            )

        # é©—è­‰æ¯å€‹è‚¡ç¥¨é …ç›®çš„å¿…è¦å­—æ®µ
        required_fields = ['symbol', 'entry_price', 'entry_date']
        for i, stock in enumerate(data):
            if not isinstance(stock, dict):
                return JSONResponse(
                    status_code=400,
                    content={"error": f"ç¬¬ {i+1} é …æ•¸æ“šæ ¼å¼éŒ¯èª¤ï¼šæ‡‰ç‚ºå°è±¡"}
                )

            for field in required_fields:
                if field not in stock:
                    return JSONResponse(
                        status_code=400,
                        content={"error": f"ç¬¬ {i+1} é …ç¼ºå°‘å¿…è¦å­—æ®µ: {field}"}
                    )

        # å‚™ä»½åŸæœ‰æ•¸æ“š
        try:
            original_data = []
            if MONITORED_STOCKS_PATH.exists():
                original_content = MONITORED_STOCKS_PATH.read_text(encoding='utf-8')
                if original_content.strip():
                    original_data = json.loads(original_content)
        except Exception as e:
            logger.warning(f"ç„¡æ³•è®€å–åŸæœ‰æ•¸æ“šé€²è¡Œå‚™ä»½: {e}")

        # ä¿å­˜æ–°æ•¸æ“š
        try:
            MONITORED_STOCKS_PATH.write_text(
                json.dumps(data, indent=2, ensure_ascii=False),
                encoding='utf-8'
            )
            logger.info(f"æˆåŠŸåŒ¯å…¥ {len(data)} ç­†ç›£æ§è‚¡ç¥¨æ•¸æ“š")

            return {
                "status": "success",
                "message": f"æˆåŠŸåŒ¯å…¥ {len(data)} ç­†ç›£æ§è‚¡ç¥¨æ•¸æ“š",
                "imported_count": len(data),
                "original_count": len(original_data),
                "timestamp": datetime.now(TZ_TAIPEI).isoformat()
            }

        except Exception as e:
            logger.error(f"ä¿å­˜åŒ¯å…¥æ•¸æ“šå¤±æ•—: {e}")
            return JSONResponse(
                status_code=500,
                content={"error": f"ä¿å­˜æ•¸æ“šå¤±æ•—: {str(e)}"}
            )

    except Exception as e:
        logger.error(f"åŒ¯å…¥ç›£æ§è‚¡ç¥¨æ•¸æ“šå¤±æ•—: {e}")
        return JSONResponse(
            status_code=500,
            content={"error": f"åŒ¯å…¥å¤±æ•—: {str(e)}"}
        )

@app.post("/api/import-trade-history")
async def import_trade_history(file: UploadFile = File(...)):
    """åŒ¯å…¥äº¤æ˜“æ­·å²æ•¸æ“š"""
    try:
        # é©—è­‰æ–‡ä»¶é¡å‹
        if not file.filename.endswith('.json'):
            return JSONResponse(
                status_code=400,
                content={"error": "åªæ”¯æ´ JSON æ–‡ä»¶æ ¼å¼"}
            )

        # è®€å–æ–‡ä»¶å…§å®¹
        content = await file.read()

        # é©—è­‰ JSON æ ¼å¼
        try:
            data = json.loads(content.decode('utf-8'))
        except json.JSONDecodeError as e:
            return JSONResponse(
                status_code=400,
                content={"error": f"JSON æ ¼å¼éŒ¯èª¤: {str(e)}"}
            )

        # é©—è­‰æ•¸æ“šçµæ§‹
        if not isinstance(data, list):
            return JSONResponse(
                status_code=400,
                content={"error": "æ•¸æ“šæ ¼å¼éŒ¯èª¤ï¼šæ‡‰ç‚ºäº¤æ˜“è¨˜éŒ„åˆ—è¡¨æ•¸çµ„"}
            )

        # é©—è­‰æ¯å€‹äº¤æ˜“è¨˜éŒ„çš„å¿…è¦å­—æ®µ
        required_fields = ['symbol', 'entry_price', 'exit_price', 'entry_date', 'exit_date']
        for i, trade in enumerate(data):
            if not isinstance(trade, dict):
                return JSONResponse(
                    status_code=400,
                    content={"error": f"ç¬¬ {i+1} é …æ•¸æ“šæ ¼å¼éŒ¯èª¤ï¼šæ‡‰ç‚ºå°è±¡"}
                )

            for field in required_fields:
                if field not in trade:
                    return JSONResponse(
                        status_code=400,
                        content={"error": f"ç¬¬ {i+1} é …ç¼ºå°‘å¿…è¦å­—æ®µ: {field}"}
                    )

        # å‚™ä»½åŸæœ‰æ•¸æ“š
        try:
            original_data = []
            if TRADE_HISTORY_PATH.exists():
                original_content = TRADE_HISTORY_PATH.read_text(encoding='utf-8')
                if original_content.strip():
                    original_data = json.loads(original_content)
        except Exception as e:
            logger.warning(f"ç„¡æ³•è®€å–åŸæœ‰æ•¸æ“šé€²è¡Œå‚™ä»½: {e}")

        # ä¿å­˜æ–°æ•¸æ“š
        try:
            TRADE_HISTORY_PATH.write_text(
                json.dumps(data, indent=2, ensure_ascii=False),
                encoding='utf-8'
            )
            logger.info(f"æˆåŠŸåŒ¯å…¥ {len(data)} ç­†äº¤æ˜“æ­·å²æ•¸æ“š")

            return {
                "status": "success",
                "message": f"æˆåŠŸåŒ¯å…¥ {len(data)} ç­†äº¤æ˜“æ­·å²æ•¸æ“š",
                "imported_count": len(data),
                "original_count": len(original_data),
                "timestamp": datetime.now(TZ_TAIPEI).isoformat()
            }

        except Exception as e:
            logger.error(f"ä¿å­˜åŒ¯å…¥æ•¸æ“šå¤±æ•—: {e}")
            return JSONResponse(
                status_code=500,
                content={"error": f"ä¿å­˜æ•¸æ“šå¤±æ•—: {str(e)}"}
            )

    except Exception as e:
        logger.error(f"åŒ¯å…¥äº¤æ˜“æ­·å²æ•¸æ“šå¤±æ•—: {e}")
        return JSONResponse(
            status_code=500,
            content={"error": f"åŒ¯å…¥å¤±æ•—: {str(e)}"}
        )

@app.get("/api/export-monitored-stocks")
def export_monitored_stocks():
    """åŒ¯å‡ºç›£æ§è‚¡ç¥¨æ•¸æ“š"""
    try:
        if MONITORED_STOCKS_PATH.exists():
            content = MONITORED_STOCKS_PATH.read_text(encoding='utf-8')
            data = json.loads(content) if content.strip() else []
        else:
            data = []

        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now(TZ_TAIPEI).strftime('%Y%m%d_%H%M%S')
        filename = f"monitored_stocks_{timestamp}.json"

        # è¿”å›æ–‡ä»¶ä¸‹è¼‰
        return Response(
            content=json.dumps(data, indent=2, ensure_ascii=False),
            media_type="application/json",
            headers={
                "Content-Disposition": f"attachment; filename={filename}",
                "Content-Type": "application/json; charset=utf-8"
            }
        )

    except Exception as e:
        logger.error(f"åŒ¯å‡ºç›£æ§è‚¡ç¥¨æ•¸æ“šå¤±æ•—: {e}")
        return JSONResponse(
            status_code=500,
            content={"error": f"åŒ¯å‡ºå¤±æ•—: {str(e)}"}
        )

@app.get("/api/export-trade-history")
def export_trade_history():
    """åŒ¯å‡ºäº¤æ˜“æ­·å²æ•¸æ“š"""
    try:
        if TRADE_HISTORY_PATH.exists():
            content = TRADE_HISTORY_PATH.read_text(encoding='utf-8')
            data = json.loads(content) if content.strip() else []
        else:
            data = []

        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now(TZ_TAIPEI).strftime('%Y%m%d_%H%M%S')
        filename = f"trade_history_{timestamp}.json"

        # è¿”å›æ–‡ä»¶ä¸‹è¼‰
        return Response(
            content=json.dumps(data, indent=2, ensure_ascii=False),
            media_type="application/json",
            headers={
                "Content-Disposition": f"attachment; filename={filename}",
                "Content-Type": "application/json; charset=utf-8"
            }
        )

    except Exception as e:
        logger.error(f"åŒ¯å‡ºäº¤æ˜“æ­·å²æ•¸æ“šå¤±æ•—: {e}")
        return JSONResponse(
            status_code=500,
            content={"error": f"åŒ¯å‡ºå¤±æ•—: {str(e)}"}
        )

# å›æ¸¬ç‹€æ…‹ç®¡ç†
backtest_status = {
    "is_running": False,
    "progress": 0,
    "message": "",
    "current_step": "",
    "logs": [],
    "result": None
}

def update_backtest_status(message: str, progress: int, step: str = "", log_message: str = ""):
    """æ›´æ–°å›æ¸¬ç‹€æ…‹"""
    global backtest_status
    backtest_status["message"] = message
    backtest_status["progress"] = progress
    backtest_status["current_step"] = step

    if log_message:
        timestamp = datetime.now(TZ_TAIPEI).strftime('%H:%M:%S')
        backtest_status["logs"].append(f"[{timestamp}] {log_message}")
        # ä¿æŒæœ€æ–°çš„100æ¢æ—¥èªŒ
        if len(backtest_status["logs"]) > 100:
            backtest_status["logs"] = backtest_status["logs"][-100:]

@app.get("/api/backtest-status")
def get_backtest_status():
    """ç²å–å›æ¸¬ç‹€æ…‹"""
    return backtest_status

@app.post("/api/run-backtest")
def run_backtest(request: dict):
    """åŸ·è¡Œå›æ¸¬"""
    global backtest_status

    if backtest_status["is_running"]:
        return {"status": "already_running", "message": "å›æ¸¬æ­£åœ¨é€²è¡Œä¸­"}

    # é©—è­‰åƒæ•¸
    symbol = request.get("symbol", "").strip().upper()
    start_date = request.get("start_date", "")
    end_date = request.get("end_date", "")

    if not symbol:
        return JSONResponse(
            status_code=400,
            content={"error": "è«‹è¼¸å…¥è‚¡ç¥¨ä»£è™Ÿ"}
        )

    if not start_date or not end_date:
        return JSONResponse(
            status_code=400,
            content={"error": "è«‹è¼¸å…¥é–‹å§‹å’ŒçµæŸæ—¥æœŸ"}
        )

    try:
        # é©—è­‰æ—¥æœŸæ ¼å¼
        from datetime import datetime
        datetime.strptime(start_date, '%Y-%m-%d')
        datetime.strptime(end_date, '%Y-%m-%d')
    except ValueError:
        return JSONResponse(
            status_code=400,
            content={"error": "æ—¥æœŸæ ¼å¼éŒ¯èª¤ï¼Œè«‹ä½¿ç”¨ YYYY-MM-DD æ ¼å¼"}
        )

    # é‡ç½®ç‹€æ…‹
    backtest_status = {
        "is_running": True,
        "progress": 0,
        "message": "æº–å‚™é–‹å§‹å›æ¸¬...",
        "current_step": "åˆå§‹åŒ–",
        "logs": [],
        "result": None
    }

    logger.info(f"é–‹å§‹å›æ¸¬: {symbol}, {start_date} to {end_date}")

    # ä½¿ç”¨ç·šç¨‹æ± åŸ·è¡Œå›æ¸¬ä»»å‹™ï¼Œé¿å…é˜»å¡API
    import threading
    thread = threading.Thread(target=run_backtest_task, args=(symbol, start_date, end_date))
    thread.daemon = True
    thread.start()

    return {"status": "started", "message": "å›æ¸¬å·²é–‹å§‹"}

def run_backtest_task(symbol: str, start_date: str, end_date: str):
    """åŸ·è¡Œå›æ¸¬ä»»å‹™ - æ”¹ç‚ºåŒæ­¥å‡½æ•¸åœ¨å¾Œå°ç·šç¨‹ä¸­åŸ·è¡Œ"""
    global backtest_status

    try:
        update_backtest_status("æ­£åœ¨åˆå§‹åŒ–å›æ¸¬ç’°å¢ƒ...", 5, "åˆå§‹åŒ–", "é–‹å§‹å›æ¸¬ç¨‹åº")

        # å°å…¥å¿…è¦çš„æ¨¡çµ„
        import yfinance as yf
        import backtester
        import pandas as pd
        import time

        update_backtest_status("æ­£åœ¨ä¸‹è¼‰è‚¡ç¥¨æ•¸æ“š...", 15, "æ•¸æ“šä¸‹è¼‰", f"æ­£åœ¨ä¸‹è¼‰ {symbol} çš„æ­·å²æ•¸æ“š")

        # é©—è­‰è‚¡ç¥¨ä»£è™Ÿä¸¦ä¸‹è¼‰æ•¸æ“š
        try:
            stock_data = yf.download(symbol, start=start_date, end=end_date, progress=False, auto_adjust=True)
            if stock_data.empty:
                raise ValueError(f"ç„¡æ³•ç²å–è‚¡ç¥¨ {symbol} çš„æ•¸æ“š")

            update_backtest_status("æ•¸æ“šä¸‹è¼‰å®Œæˆ", 25, "æ•¸æ“šé©—è­‰", f"æˆåŠŸä¸‹è¼‰ {len(stock_data)} å¤©çš„æ•¸æ“š")

        except Exception as e:
            update_backtest_status("æ•¸æ“šä¸‹è¼‰å¤±æ•—", 0, "éŒ¯èª¤", f"ä¸‹è¼‰å¤±æ•—: {str(e)}")
            backtest_status["is_running"] = False
            return

        update_backtest_status("æ­£åœ¨æº–å‚™å›æ¸¬ç¨‹åº...", 35, "ç¨‹åºæº–å‚™", "è¨­ç½®å›æ¸¬åƒæ•¸")

        # ä¿å­˜åŸå§‹å€¼
        original_start = backtester.START_DATE
        original_end = backtester.END_DATE

        try:
            # ä¿®æ”¹å…¨å±€è®Šé‡
            backtester.START_DATE = start_date
            backtester.END_DATE = end_date

            update_backtest_status("è¼‰å…¥è‚¡ç¥¨æ•¸æ“š...", 45, "æ•¸æ“šè¼‰å…¥", f"è¼‰å…¥ {symbol} çš„æ­·å²æ•¸æ“š")

            # ä½¿ç”¨åŸå§‹çš„preload_dataå’ŒBacktester
            watchlist = [symbol]
            all_data = backtester.preload_data(watchlist, backtester.START_DATE, backtester.END_DATE)

            if not all_data:
                update_backtest_status("æ•¸æ“šè¼‰å…¥å¤±æ•—", 0, "éŒ¯èª¤", "ç„¡æ³•è¼‰å…¥è‚¡ç¥¨æ•¸æ“š")
                backtest_status["is_running"] = False
                return

            # å‰µå»ºè‡ªå®šç¾©çš„Backtesterä¾†å³æ™‚è¼¸å‡ºæ—¥èªŒ
            class RealTimeBacktester(backtester.Backtester):
                def __init__(self, symbols, all_historical_data):
                    super().__init__(symbols, all_historical_data)
                    self.total_days = len(self.trading_days)
                    self.current_day_index = 0

                def run(self):
                    update_backtest_status("é–‹å§‹é€æ—¥æ¨¡æ“¬äº¤æ˜“...", 55, "æ¨¡æ“¬äº¤æ˜“", f"å…± {self.total_days} å€‹äº¤æ˜“æ—¥")

                    for i in range(len(self.trading_days) - 1):
                        current_day = self.trading_days[i]
                        next_day = self.trading_days[i+1]
                        self.current_day_index = i

                        # è¨ˆç®—é€²åº¦
                        progress = 55 + int((i / self.total_days) * 30)  # 55% åˆ° 85%

                        # å³æ™‚æ›´æ–°æ—¥èªŒ
                        date_str = current_day.strftime('%Y-%m-%d')

                        # æª¢æŸ¥å‡ºå ´
                        exit_count_before = len([t for t in self.trade_log if t.get('exit_date')])
                        self.check_and_execute_exits(current_day, next_day)
                        exit_count_after = len([t for t in self.trade_log if t.get('exit_date')])

                        if exit_count_after > exit_count_before:
                            for trade in self.trade_log[exit_count_before:exit_count_after]:
                                pnl = trade.get('profit_loss_usd', 0)
                                pnl_pct = trade.get('profit_loss_pct', 0)
                                result_text = "ç²åˆ©" if pnl > 0 else "è™§æ"
                                update_backtest_status(f"å‡ºå ´ä¿¡è™Ÿ", progress, "äº¤æ˜“åŸ·è¡Œ",
                                                     f"ğŸ”´ {trade['symbol']} å‡ºå ´ @ ${trade.get('exit_price', 0):.2f} ({result_text}: ${pnl:.2f}, {pnl_pct:.1f}%)")

                        # æª¢æŸ¥é€²å ´
                        entry_count_before = len([t for t in self.trade_log if t.get('entry_date')])
                        self.check_and_execute_entries(current_day, next_day)
                        entry_count_after = len([t for t in self.trade_log if t.get('entry_date')])

                        if entry_count_after > entry_count_before:
                            for trade in self.trade_log[entry_count_before:entry_count_after]:
                                update_backtest_status(f"é€²å ´ä¿¡è™Ÿ", progress, "äº¤æ˜“åŸ·è¡Œ",
                                                     f"ğŸŸ¢ {trade['symbol']} é€²å ´ @ ${trade.get('entry_price', 0):.2f}")

                        # æ›´é »ç¹çš„é€²åº¦æ›´æ–°
                        if i % 3 == 0 or i < 15:  # å‰15å¤©æ¯å¤©æ›´æ–°ï¼Œä¹‹å¾Œæ¯3å¤©æ›´æ–°
                            current_trades = len(self.trade_log)
                            update_backtest_status(f"æ¨¡æ“¬äº¤æ˜“æ—¥: {date_str}", progress, "æ¨¡æ“¬äº¤æ˜“",
                                                 f"[{i+1}/{self.total_days}] æª¢æŸ¥ {date_str} äº¤æ˜“æ©Ÿæœƒ")

                        # æ·»åŠ å»¶é²è®“å‰ç«¯æœ‰æ™‚é–“ç²å–æ›´æ–°
                        if i % 5 == 0:
                            time.sleep(0.05)  # 50æ¯«ç§’å»¶é²ï¼Œè®“å‰ç«¯æœ‰æ™‚é–“ç²å–ç‹€æ…‹

                    update_backtest_status("æ¨¡æ“¬äº¤æ˜“å®Œæˆ", 85, "è¨ˆç®—çµæœ", f"ç¸½å…±ç”¢ç”Ÿ {len(self.trade_log)} ç­†äº¤æ˜“")

            # å‰µå»ºä¸¦é‹è¡Œå›æ¸¬å™¨
            bt = RealTimeBacktester(watchlist, all_data)
            bt.run()

            # è™•ç†çµæœ
            if bt.trade_log:
                df_log = pd.DataFrame(bt.trade_log)

                total_trades = len(df_log)
                winning_trades = df_log[df_log['profit_loss_usd'] > 0]
                losing_trades = df_log[df_log['profit_loss_usd'] <= 0]

                win_rate = (len(winning_trades) / total_trades) * 100 if total_trades > 0 else 0
                total_pnl = df_log['profit_loss_usd'].sum()

                avg_profit = winning_trades['profit_loss_usd'].mean() if len(winning_trades) > 0 else 0
                avg_loss = losing_trades['profit_loss_usd'].mean() if len(losing_trades) > 0 else 0

                profit_factor = abs(winning_trades['profit_loss_usd'].sum() / losing_trades['profit_loss_usd'].sum()) if len(losing_trades) > 0 and losing_trades['profit_loss_usd'].sum() != 0 else float('inf')

                avg_holding_period = df_log['holding_period_days'].mean()

                backtest_result = {
                    "symbol": symbol,
                    "start_date": start_date,
                    "end_date": end_date,
                    "total_trades": total_trades,
                    "win_rate": round(win_rate, 2),
                    "total_pnl": round(total_pnl, 2),
                    "avg_profit": round(avg_profit, 2),
                    "avg_loss": round(avg_loss, 2),
                    "profit_factor": round(profit_factor, 2) if profit_factor != float('inf') else "âˆ",
                    "avg_holding_period": round(avg_holding_period, 1),
                    "trades": df_log.to_dict('records')
                }

                backtest_status["result"] = backtest_result
                update_backtest_status("å›æ¸¬å®Œæˆ", 100, "å®Œæˆ",
                                     f"âœ… å®Œæˆï¼{total_trades} ç­†äº¤æ˜“ï¼Œå‹ç‡ {win_rate:.1f}%ï¼Œç¸½ç›ˆè™§ ${total_pnl:.2f}")
            else:
                backtest_result = {
                    "symbol": symbol,
                    "start_date": start_date,
                    "end_date": end_date,
                    "total_trades": 0,
                    "win_rate": 0,
                    "total_pnl": 0,
                    "avg_profit": 0,
                    "avg_loss": 0,
                    "profit_factor": 0,
                    "avg_holding_period": 0,
                    "trades": []
                }
                backtest_status["result"] = backtest_result
                update_backtest_status("å›æ¸¬å®Œæˆ", 100, "å®Œæˆ", "âœ… å›æ¸¬å®Œæˆï¼ŒæœŸé–“å…§æœªç”¢ç”Ÿäº¤æ˜“ä¿¡è™Ÿ")

        finally:
            # æ¢å¾©åŸå§‹å€¼
            backtester.START_DATE = original_start
            backtester.END_DATE = original_end

    except Exception as e:
        logger.error(f"ç›´æ¥å›æ¸¬åŸ·è¡Œå¤±æ•—: {e}")
        update_backtest_status("å›æ¸¬åŸ·è¡Œå¤±æ•—", 0, "éŒ¯èª¤", f"åŸ·è¡ŒéŒ¯èª¤: {str(e)}")
        backtest_status["is_running"] = False
        return

    except Exception as e:
        logger.error(f"å›æ¸¬ä»»å‹™å¤±æ•—: {e}")
        update_backtest_status("å›æ¸¬å¤±æ•—", 0, "éŒ¯èª¤", f"ç³»çµ±éŒ¯èª¤: {str(e)}")

    finally:
        backtest_status["is_running"] = False



# éœæ…‹æª”æ¡ˆ - æ”¾åœ¨ API è·¯ç”±ä¹‹å¾Œ
if STATIC_DIR.exists():
    logger.info(f"Mounting static files from {STATIC_DIR}")
    app.mount("/", StaticFiles(directory=str(STATIC_DIR), html=True), name="static")
else:
    logger.error(f"Static directory not found at {STATIC_DIR}")

# SPA fallback
@app.middleware("http")
async def spa_fallback(request: Request, call_next):
    if request.url.path.startswith("/api"):
        return await call_next(request)
    response = await call_next(request)
    if response.status_code == 404:
        index_path = STATIC_DIR / "index.html"
        if index_path.exists():
            logger.info(f"Serving index.html for path: {request.url.path}")
            return FileResponse(index_path)
        else:
            logger.error(f"Index file not found at {index_path}")
            return JSONResponse(
                status_code=404,
                content={"error": "Frontend not built"}
            )
    return response

if __name__ == "__main__":
    try:
        import uvicorn
        uvicorn.run(app, host="0.0.0.0", port=8080)
    except ImportError:
        logger.error("Uvicorn is not installed. Please run 'pip install uvicorn' to start the server.")
