#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çµ±ä¸€çš„æ–‡ä»¶è·¯å¾‘ç®¡ç†æ¨¡å¡Š
ç¢ºä¿æ‰€æœ‰çµ„ä»¶ä½¿ç”¨ç›¸åŒçš„æ–‡ä»¶è·¯å¾‘ï¼Œé¿å…è®€å¯«ä¸ä¸€è‡´å•é¡Œ
"""

import os
import json
from pathlib import Path

class PathManager:
    """çµ±ä¸€ç®¡ç†æ‰€æœ‰æ•¸æ“šæ–‡ä»¶çš„è·¯å¾‘"""

    def __init__(self):
        self.base_dir = Path(__file__).parent.parent
        self.data_dir = self._get_unified_data_dir()
        self._paths = {}
        self._initialize_paths()

    def _get_unified_data_dir(self):
        """ç²å–çµ±ä¸€çš„æ•¸æ“šç›®éŒ„"""
        # æª¢æ¸¬ Zeabur ç’°å¢ƒ
        is_zeabur = os.environ.get("ZEABUR") == "1" or "zeabur" in os.environ.get("HOSTNAME", "").lower()

        # æ›´æº–ç¢ºçš„å®¹å™¨ç’°å¢ƒæª¢æ¸¬
        is_container = (
            Path("/app").exists() and
            (os.environ.get("CONTAINER_ENV") == "true" or
             os.environ.get("PORT") is not None or  # Zeabur/å®¹å™¨é€šå¸¸è¨­ç½® PORT ç’°å¢ƒè®Šæ•¸
             Path("/proc/1/cgroup").exists())  # Linux å®¹å™¨ç‰¹å¾µ
        )

        if is_zeabur:
            # Zeabur ç’°å¢ƒï¼šä½¿ç”¨å¯å¯«çš„ç›®éŒ„
            # å˜—è©¦å¤šå€‹å¯èƒ½çš„å¯å¯«ä½ç½®
            possible_dirs = [
                Path("/tmp/data"),           # è‡¨æ™‚ç›®éŒ„é€šå¸¸å¯å¯«
                Path("/app/backend"),        # backend ç›®éŒ„å¯èƒ½å¯å¯«
                Path("/app"),                # æ‡‰ç”¨æ ¹ç›®éŒ„
                Path("/var/tmp/data")        # å¦ä¸€å€‹è‡¨æ™‚ç›®éŒ„
            ]

            for data_dir in possible_dirs:
                try:
                    data_dir.mkdir(parents=True, exist_ok=True)
                    # æ¸¬è©¦å¯«å…¥æ¬Šé™
                    test_file = data_dir / "test_write.tmp"
                    test_file.write_text("test")
                    test_file.unlink()
                    print(f"âœ… Zeabur ç’°å¢ƒä½¿ç”¨å¯å¯«ç›®éŒ„: {data_dir}")

                    # é·ç§»ç¾æœ‰æ•¸æ“šæ–‡ä»¶
                    self._migrate_data_files(data_dir)
                    return data_dir
                except (PermissionError, OSError) as e:
                    print(f"âš ï¸  ç›®éŒ„ {data_dir} ä¸å¯å¯«: {e}")
                    continue

            # å¦‚æœéƒ½ä¸å¯å¯«ï¼Œå›é€€åˆ° /app/dataï¼ˆåªè®€æ¨¡å¼ï¼‰
            print("âš ï¸  æ‰€æœ‰ç›®éŒ„éƒ½ä¸å¯å¯«ï¼Œä½¿ç”¨åªè®€æ¨¡å¼")
            data_dir = Path("/app/data")

        elif is_container:
            # å…¶ä»–å®¹å™¨ç’°å¢ƒï¼šä½¿ç”¨ /app/data
            data_dir = Path("/app/data")
        else:
            # æœ¬åœ°ç’°å¢ƒï¼šä½¿ç”¨é …ç›®æ ¹ç›®éŒ„ä¸‹çš„ data
            data_dir = self.base_dir / "data"

        # ç¢ºä¿æ•¸æ“šç›®éŒ„å­˜åœ¨
        try:
            data_dir.mkdir(parents=True, exist_ok=True)
            print(f"Using unified data directory: {data_dir}")
        except PermissionError:
            print(f"Cannot create data directory {data_dir}, using read-only access")

        return data_dir

    def _migrate_data_files(self, target_dir):
        """é·ç§»ç¾æœ‰æ•¸æ“šæ–‡ä»¶åˆ°å¯å¯«ç›®éŒ„"""
        source_dir = Path("/app/data")
        if not source_dir.exists():
            return

        files_to_migrate = [
            "analysis_result.json",
            "monitored_stocks.json",
            "trade_history.json"
        ]

        for filename in files_to_migrate:
            source_file = source_dir / filename
            target_file = target_dir / filename

            if source_file.exists() and not target_file.exists():
                try:
                    # è¤‡è£½æ–‡ä»¶å…§å®¹
                    content = source_file.read_text(encoding='utf-8')
                    target_file.write_text(content, encoding='utf-8')
                    print(f"âœ… é·ç§»æ–‡ä»¶: {source_file} â†’ {target_file}")
                except Exception as e:
                    print(f"âš ï¸  é·ç§»æ–‡ä»¶å¤±æ•— {filename}: {e}")

    def _initialize_paths(self):
        """åˆå§‹åŒ–æ‰€æœ‰æ–‡ä»¶è·¯å¾‘"""
        files = {
            "analysis_result.json": self.data_dir / "analysis_result.json",
            "monitored_stocks.json": self.data_dir / "monitored_stocks.json",
            "trade_history.json": self.data_dir / "trade_history.json"
        }

        for filename, path in files.items():
            self._paths[filename] = path
            self._ensure_file_exists(path, filename)
    

    

    
    def _ensure_file_exists(self, path, filename):
        """ç¢ºä¿æ–‡ä»¶å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨å‰‡å‰µå»ºç©ºæ–‡ä»¶"""
        try:
            # å˜—è©¦å‰µå»ºç›®éŒ„ï¼ˆå¿½ç•¥æ¬Šé™éŒ¯èª¤ï¼‰
            try:
                path.parent.mkdir(parents=True, exist_ok=True)
            except PermissionError:
                print(f"Cannot create directory for {filename}, using existing path")

            if not path.exists():
                try:
                    if filename == "analysis_result.json":
                        empty_data = {
                            "result": [],
                            "timestamp": "",
                            "analysis_date": "",
                            "total_stocks": 0,
                            "analyzed_stocks": 0
                        }
                    else:
                        empty_data = []

                    with open(path, 'w', encoding='utf-8') as f:
                        json.dump(empty_data, f, indent=2, ensure_ascii=False)
                    print(f"Created empty {filename} at: {path}")
                except (PermissionError, OSError) as e:
                    print(f"Cannot create {filename} at {path}: {e}")
        except Exception as e:
            print(f"Failed to ensure {filename} exists: {e}")
    
    def get_path(self, filename):
        """ç²å–æŒ‡å®šæ–‡ä»¶çš„è·¯å¾‘"""
        return self._paths.get(filename)
    
    def get_analysis_path(self):
        """ç²å–åˆ†æçµæœæ–‡ä»¶è·¯å¾‘"""
        return self._paths["analysis_result.json"]
    
    def get_monitored_stocks_path(self):
        """ç²å–ç›£æ§è‚¡ç¥¨æ–‡ä»¶è·¯å¾‘"""
        return self._paths["monitored_stocks.json"]
    
    def get_trade_history_path(self):
        """ç²å–äº¤æ˜“æ­·å²æ–‡ä»¶è·¯å¾‘"""
        return self._paths["trade_history.json"]
    
    def sync_files(self):
        """åŒæ­¥æ–‡ä»¶åˆ°æ‰€æœ‰å¯èƒ½çš„ä½ç½®ï¼ˆç”¨æ–¼å…¼å®¹æ€§ï¼‰"""
        print("Using unified data directory - no sync needed")
        # çµ±ä¸€è·¯å¾‘å¾Œä¸éœ€è¦åŒæ­¥ï¼Œæ‰€æœ‰çµ„ä»¶éƒ½ä½¿ç”¨ç›¸åŒçš„æ–‡ä»¶ä½ç½®
    
    def get_info(self):
        """ç²å–è·¯å¾‘ç®¡ç†å™¨çš„ä¿¡æ¯"""
        info = {
            "environment": "container" if Path("/app/data").exists() else "local",
            "base_dir": str(self.base_dir),
            "paths": {name: str(path) for name, path in self._paths.items()},
            "file_exists": {name: path.exists() for name, path in self._paths.items()},
            "file_sizes": {}
        }
        
        for name, path in self._paths.items():
            try:
                info["file_sizes"][name] = path.stat().st_size if path.exists() else 0
            except Exception:
                info["file_sizes"][name] = 0
        
        return info

# å…¨å±€è·¯å¾‘ç®¡ç†å™¨å¯¦ä¾‹
path_manager = PathManager()

# ä¾¿æ·å‡½æ•¸
def get_analysis_path():
    return path_manager.get_analysis_path()

def get_monitored_stocks_path():
    return path_manager.get_monitored_stocks_path()

def get_trade_history_path():
    return path_manager.get_trade_history_path()

def sync_all_files():
    """åŒæ­¥æ‰€æœ‰æ–‡ä»¶åˆ°å…¼å®¹ä½ç½®"""
    path_manager.sync_files()

def get_path_info():
    """ç²å–è·¯å¾‘ä¿¡æ¯"""
    return path_manager.get_info()

if __name__ == "__main__":
    # æ¸¬è©¦è·¯å¾‘ç®¡ç†å™¨
    print("ğŸ”§ è·¯å¾‘ç®¡ç†å™¨æ¸¬è©¦")
    print("=" * 50)
    
    info = get_path_info()
    print(f"ç’°å¢ƒ: {info['environment']}")
    print(f"åŸºç¤ç›®éŒ„: {info['base_dir']}")
    print()
    
    print("æ–‡ä»¶è·¯å¾‘:")
    for name, path in info['paths'].items():
        exists = info['file_exists'][name]
        size = info['file_sizes'][name]
        status = f"âœ… {size} bytes" if exists and size > 0 else "âŒ ä¸å­˜åœ¨æˆ–ç‚ºç©º"
        print(f"  {name}: {path} - {status}")
    
    print("\nåŒæ­¥æ–‡ä»¶...")
    sync_all_files()
    print("åŒæ­¥å®Œæˆï¼")
